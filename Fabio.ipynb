{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "46c9a4e1-628c-4a6a-a41f-eb3f9901833f",
   "metadata": {},
   "source": [
    "PCLab#5 - Group 2 - Emanuele Sala, Luca Soleri, Fabio Stefana"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb8de0ea-51ef-4752-84f4-4a685bc95211",
   "metadata": {},
   "source": [
    "<div style=\"border: 4px solid #007bff; padding: 10px; background-color: #e9f5ff; border-radius: 5px;\">\n",
    "    <h1 style=\"color: #007bff;\">Importing libraries and Dataset</h1>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "63ea0fff-1d3a-453b-8cfb-60cab09f3e46",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f945631-57da-4f54-a7fb-e7039685746d",
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = \"data/sigwatch_data\"\n",
    "df_list = []\n",
    "\n",
    "for file in os.listdir(directory):\n",
    "    if file.endswith(\".dta\"):\n",
    "        file_path = os.path.join(directory, file)\n",
    "        temp_df = pd.read_stata(file_path)\n",
    "        df_list.append(temp_df)\n",
    "        \n",
    "df = pd.concat(df_list, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "104fb569-7f87-4c05-98bd-40faeda213b6",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "<div style=\"border: 4px solid #007bff; padding: 10px; background-color: #e9f5ff; border-radius: 5px;\">\n",
    "    <h1 style=\"color: #007bff;\">Preliminary data exploration</h1>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c896bfd-39b3-4d7d-a01d-55f96356c7cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# With this filter we keep only the banks\n",
    "df = df[df[\"corp_industry_sector1\"] == \"Finance\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "670aeac1-6bbd-4c2c-9d4d-8ee1c2558dd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# And with this filter we only keep the countries form the US, UK or EU\n",
    "countries = ['Austria',\n",
    "             'US',\n",
    "             'Denmark',\n",
    "             'UK',\n",
    "             'Germany',\n",
    "             'Luxembourg',\n",
    "             'France',\n",
    "             'Italy',\n",
    "             'Netherlands',\n",
    "             'Belgium',\n",
    "             'Sweden',\n",
    "             'Spain',\n",
    "             'Ireland',\n",
    "             'Portugal',\n",
    "             'Poland',\n",
    "             'Finland',\n",
    "             'USA',\n",
    "             'Croatia',\n",
    "             'Bulgaria',\n",
    "             'Montenegro',\n",
    "             'Bosnia and Herzegovina']\n",
    "\n",
    "df = df[df['country_corp'].isin(countries)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a8f2091-57c9-4064-8a64-95547e1549d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We count the unique number of ud_archive as some have more than one row but still count as one isngle campaing\n",
    "n_of_campaigns = len(list(df[\"uid_archive\"].unique()))\n",
    "print(f\"There are {n_of_campaigns} unique campaigns for US UK and EU banks\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5baf485d-3af8-487a-a220-d1d91004a01d",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_ngo_columns = []\n",
    "for i in range(5):\n",
    "    i = i+1\n",
    "    ngo_column_number = f\"ngo_name{i}\"\n",
    "    ngo_col = list(df[ngo_column_number])\n",
    "    list_of_ngo_columns += ngo_col\n",
    "unique_ngos = list(set(list_of_ngo_columns))\n",
    "\n",
    "# we do -1 because we have to account for the null value\n",
    "print(f\"There are {len(unique_ngos) - 1} unique NGO organizations involved in this dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38a84c67-64d6-49a5-bfc7-09587ccfac06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Numero di aziende targettate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c4d16f5-0ca2-49f6-9512-6079242c6b33",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_we_want = [\"uid_archive\", \n",
    "                   \"date\", \n",
    "                   \"company\",\n",
    "                   'country_corp', # Country of the Company\n",
    "                   'corp_industry_sector1', # Industry of the company\n",
    "                   'company_parent',\n",
    "                   'company_parent_country',\n",
    "                   \"sentiment\",\n",
    "                   'issue_name1',\n",
    "                   'issue_name2',\n",
    "                   'issue_name3']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed4daac4-7cea-451a-b66f-e961af076dd2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2cb34e4a-836c-4c8b-b106-9547283521ef",
   "metadata": {},
   "source": [
    "<div style=\"border: 4px solid #007bff; padding: 10px; background-color: #e9f5ff; border-radius: 5px;\">\n",
    "    <h1 style=\"color: #007bff;\">Task #4 : estimate parameters of the CAPM </h1>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05feeeb7-816b-4005-84db-86dd30f4ddac",
   "metadata": {},
   "source": [
    "IMPORTANT NOTE\n",
    "\n",
    "- Price Index: This index only reflects the price movements of a stock without considering dividends or other distributions. It’s a pure measure of price appreciation, so when you use the Price Index, you’re capturing the changes in the stock’s market price alone.\n",
    "- Total Return Index: This includes both price changes and the effect of dividends reinvested back into the stock. If the bank pays dividends, these dividends are considered to be reinvested, adding to the growth of the index. This index provides a more comprehensive view of the stock’s overall return by including income from dividends, making it useful for capturing the full picture of what an investor earns from holding the stock.\n",
    "\n",
    "For CAPM estimation, you typically need the Total Return Index. CAPM aims to model the total returns an investor would expect, factoring in all sources of return. Calculating returns using the Total Return Index allows you to include dividends, which are a critical component of a stock’s performance from an investor’s perspective."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "163a8bae-b258-4861-8c63-d9713cb0354f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def read_banks_ri(directory):\n",
    "    # banks_ri.xlsm has the total return for each bank\n",
    "    banks_ri = pd.ExcelFile(directory)\n",
    "    \n",
    "    # Each workbook is divided into sheets that divide the banks into different countires\n",
    "    # the first sheet is a request table so we will ignore it\n",
    "    banks_ri_sheets = banks_ri.sheet_names[1:]\n",
    "    \n",
    "    # We are gonna read all the different sheets and put them into a dataframe, store it \n",
    "    # into a list and concatenate them all toghether so we will have a big df with all the \n",
    "    # banks_ri info in it.\n",
    "    # Since all the sheets have a column for the date, we will only read it for the first\n",
    "    # sheet and skip it for the others.\n",
    "    first_df = banks_ri.parse(banks_ri_sheets[0])\n",
    "    first_df = first_df.rename(columns={first_df.columns[0]: \"Date\"})\n",
    "    other_dfs = [banks_ri.parse(sheet_name).iloc[:, 1:] for sheet_name in banks_ri_sheets[1:]]\n",
    "    \n",
    "    banks_ri_df = pd.concat([first_df] + other_dfs, axis=1)\n",
    "    return banks_ri_df\n",
    "\n",
    "def clean_banks_ri(banks_ri_df):\n",
    "    # Rename columns so that they have cleaner names\n",
    "    rename_dict = {\"Date\": \"Date\"}\n",
    "    for col in banks_ri_df.columns[1:]:\n",
    "        rename_dict[col] = col[:-17] + \"_TR\"\n",
    "    banks_ri_df.rename(columns=rename_dict, inplace=True)\n",
    "    \n",
    "    # As we have 158 banks, we will drop all the banks that are marked as Dead, this is a simple \n",
    "    # solution around this problem and we are only doing this because we can afford to do so \n",
    "    # seeing how many banks we have. \n",
    "    # With this operation we will be dropping only 3 banks.\n",
    "    dead_banks = []\n",
    "    for col in banks_ri_df.columns[1:]:\n",
    "        if \"dead\" in col.lower():\n",
    "            dead_banks.append(col)\n",
    "    banks_ri_df.drop(dead_banks, axis = 1, inplace = True)\n",
    "    return banks_ri_df\n",
    "\n",
    "banks_ri_df = read_banks_ri(\"data/banks_data_bocconi/banks_ri.xlsm\")\n",
    "banks_ri_df = clean_banks_ri(banks_ri_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "37534eb4-655e-4758-8ea2-d66504fd6f82",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_banks_pi(directory):\n",
    "    # banks_ri.xlsm has the total return for each bank\n",
    "    banks_pi = pd.ExcelFile(directory)\n",
    "    \n",
    "    # Each workbook is divided into sheets that divide the banks into different countires\n",
    "    # the first sheet is a request table so we will ignore it\n",
    "    banks_pi_sheets = banks_pi.sheet_names[1:]\n",
    "    \n",
    "    # We are gonna read all the different sheets and put them into a dataframe, store it \n",
    "    # into a list and concatenate them all toghether so we will have a big df with all the \n",
    "    # banks_ri info in it.\n",
    "    # Since all the sheets have a column for the date, we will only read it for the first\n",
    "    # sheet and skip it for the others.\n",
    "    first_df = banks_pi.parse(banks_pi_sheets[0])\n",
    "    first_df = first_df.rename(columns={first_df.columns[0]: \"Date\"})\n",
    "    other_dfs = [banks_pi.parse(sheet_name).iloc[:, 1:] for sheet_name in banks_pi_sheets[1:]]\n",
    "    \n",
    "    banks_ri_df = pd.concat([first_df] + other_dfs, axis=1)\n",
    "    return banks_ri_df\n",
    "\n",
    "def clean_banks_pi(banks_pi_df):\n",
    "    # Rename columns so that they have cleaner names\n",
    "    rename_dict = {\"Date\": \"Date\"}\n",
    "    for col in banks_pi_df.columns[1:]:\n",
    "        rename_dict[col] = col[:-14] + \"_PI\"\n",
    "    banks_pi_df.rename(columns=rename_dict, inplace=True)\n",
    "    \n",
    "    # As we have 158 banks, we will drop all the banks that are marked as Dead, this is a simple \n",
    "    # solution around this problem and we are only doing this because we can afford to do so \n",
    "    # seeing how many banks we have. \n",
    "    # With this operation we will be dropping only 3 banks.\n",
    "    dead_banks = []\n",
    "    for col in banks_pi_df.columns[1:]:\n",
    "        if \"dead\" in col.lower():\n",
    "            dead_banks.append(col)\n",
    "    banks_pi_df.drop(dead_banks, axis = 1, inplace = True)\n",
    "    return banks_pi_df\n",
    "\n",
    "banks_pi_df = read_banks_pi(\"data/banks_data_bocconi/banks_pi.xlsm\")\n",
    "banks_pi_df = clean_banks_pi(banks_pi_df)\n",
    "# We drop the date form this df so that when we concatenate them there is no double \"Date\" column\n",
    "banks_pi_df.drop(\"Date\", axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d380c3a3-46d4-4605-b6fd-5856557895f0",
   "metadata": {},
   "source": [
    "The banks_pi dataset contains 3 more banks than the banks_pi dataset, those banks are all 3 located in Austria and they are:\n",
    "- ERSTE GROUP BANK\n",
    "- RAIFFEISEN BANK INTL\n",
    "- VOLKSBANK VBG.PARTN.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d43932ec-057c-4c82-9b6a-22fc0ed9c76b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3857"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bank_data = pd.concat([banks_ri_df, banks_pi_df], axis=1)\n",
    "bank_data\n",
    "\n",
    "# Delete superflous dfs to free up memory\n",
    "del banks_ri_df, banks_pi_df\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c423fb3b-eecf-4298-91f7-dcc77b237a29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>AAREAL BANK_TR</th>\n",
       "      <th>COMDIRECT BANK_TR</th>\n",
       "      <th>COMMERZBANK_TR</th>\n",
       "      <th>DT.PFANDBRIEFBANK_TR</th>\n",
       "      <th>PROCREDIT HOLDING_TR</th>\n",
       "      <th>UMWELTBANK_TR</th>\n",
       "      <th>ALLIANZ_TR</th>\n",
       "      <th>DEUTSCHE BANK_TR</th>\n",
       "      <th>BANQUE NATIONALE DE BELGIQUE_TR</th>\n",
       "      <th>...</th>\n",
       "      <th>CLOSE BROTHERS GROUP_PI</th>\n",
       "      <th>VIRGIN MONEY UK_PI</th>\n",
       "      <th>HSBC HOLDINGS_PI</th>\n",
       "      <th>LLOYDS BANKING GROUP_PI</th>\n",
       "      <th>METRO BANK_PI</th>\n",
       "      <th>ROYAL BANK OF SCTL.GP._PI</th>\n",
       "      <th>STANDARD CHARTERED_PI</th>\n",
       "      <th>ADMIRAL GROUP_PI</th>\n",
       "      <th>ALLIANCE TRUST_PI</th>\n",
       "      <th>SAGA GROUP_PI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2008-01-01</td>\n",
       "      <td>182.27</td>\n",
       "      <td>33.09</td>\n",
       "      <td>974.59</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>260.15</td>\n",
       "      <td>3364.43</td>\n",
       "      <td>1937.46</td>\n",
       "      <td>2658.11</td>\n",
       "      <td>...</td>\n",
       "      <td>8202.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>784.5</td>\n",
       "      <td>137.4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11418.8</td>\n",
       "      <td>8372.5</td>\n",
       "      <td>400.0</td>\n",
       "      <td>3044.2</td>\n",
       "      <td>854.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2008-01-02</td>\n",
       "      <td>183.81</td>\n",
       "      <td>33.05</td>\n",
       "      <td>956.43</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>259.22</td>\n",
       "      <td>3304.22</td>\n",
       "      <td>1900.87</td>\n",
       "      <td>2684.50</td>\n",
       "      <td>...</td>\n",
       "      <td>8198.2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>778.0</td>\n",
       "      <td>136.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11264.5</td>\n",
       "      <td>8322.5</td>\n",
       "      <td>398.2</td>\n",
       "      <td>3037.9</td>\n",
       "      <td>854.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2008-01-03</td>\n",
       "      <td>181.73</td>\n",
       "      <td>33.05</td>\n",
       "      <td>944.94</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>261.69</td>\n",
       "      <td>3285.59</td>\n",
       "      <td>1900.00</td>\n",
       "      <td>2682.82</td>\n",
       "      <td>...</td>\n",
       "      <td>8202.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>781.2</td>\n",
       "      <td>137.3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11380.3</td>\n",
       "      <td>8286.2</td>\n",
       "      <td>400.0</td>\n",
       "      <td>3059.0</td>\n",
       "      <td>854.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2008-01-04</td>\n",
       "      <td>173.31</td>\n",
       "      <td>33.09</td>\n",
       "      <td>939.75</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>263.24</td>\n",
       "      <td>3220.61</td>\n",
       "      <td>1881.60</td>\n",
       "      <td>2641.91</td>\n",
       "      <td>...</td>\n",
       "      <td>8332.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>771.0</td>\n",
       "      <td>132.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10885.2</td>\n",
       "      <td>8181.8</td>\n",
       "      <td>388.4</td>\n",
       "      <td>2991.6</td>\n",
       "      <td>854.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2008-01-07</td>\n",
       "      <td>167.91</td>\n",
       "      <td>33.20</td>\n",
       "      <td>943.08</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>259.37</td>\n",
       "      <td>3179.94</td>\n",
       "      <td>1880.52</td>\n",
       "      <td>2632.54</td>\n",
       "      <td>...</td>\n",
       "      <td>8336.3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>776.1</td>\n",
       "      <td>131.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10756.6</td>\n",
       "      <td>8209.0</td>\n",
       "      <td>384.4</td>\n",
       "      <td>2993.7</td>\n",
       "      <td>854.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3211</th>\n",
       "      <td>2020-04-22</td>\n",
       "      <td>126.90</td>\n",
       "      <td>86.08</td>\n",
       "      <td>21.01</td>\n",
       "      <td>81.91</td>\n",
       "      <td>40.14</td>\n",
       "      <td>1387.93</td>\n",
       "      <td>6352.29</td>\n",
       "      <td>201.17</td>\n",
       "      <td>2595.15</td>\n",
       "      <td>...</td>\n",
       "      <td>9005.5</td>\n",
       "      <td>34.6</td>\n",
       "      <td>433.6</td>\n",
       "      <td>17.6</td>\n",
       "      <td>4.7</td>\n",
       "      <td>321.6</td>\n",
       "      <td>2165.4</td>\n",
       "      <td>830.2</td>\n",
       "      <td>5894.7</td>\n",
       "      <td>854.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3212</th>\n",
       "      <td>2020-04-23</td>\n",
       "      <td>125.18</td>\n",
       "      <td>87.56</td>\n",
       "      <td>21.56</td>\n",
       "      <td>81.53</td>\n",
       "      <td>40.47</td>\n",
       "      <td>1382.27</td>\n",
       "      <td>6220.43</td>\n",
       "      <td>206.42</td>\n",
       "      <td>2620.59</td>\n",
       "      <td>...</td>\n",
       "      <td>9204.0</td>\n",
       "      <td>35.6</td>\n",
       "      <td>438.7</td>\n",
       "      <td>17.9</td>\n",
       "      <td>4.6</td>\n",
       "      <td>326.9</td>\n",
       "      <td>2216.9</td>\n",
       "      <td>828.4</td>\n",
       "      <td>5920.0</td>\n",
       "      <td>854.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3213</th>\n",
       "      <td>2020-04-24</td>\n",
       "      <td>127.08</td>\n",
       "      <td>87.16</td>\n",
       "      <td>21.35</td>\n",
       "      <td>80.14</td>\n",
       "      <td>40.81</td>\n",
       "      <td>1348.28</td>\n",
       "      <td>6189.82</td>\n",
       "      <td>196.74</td>\n",
       "      <td>2582.43</td>\n",
       "      <td>...</td>\n",
       "      <td>9005.5</td>\n",
       "      <td>35.1</td>\n",
       "      <td>430.0</td>\n",
       "      <td>17.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>321.3</td>\n",
       "      <td>2128.7</td>\n",
       "      <td>839.3</td>\n",
       "      <td>5861.1</td>\n",
       "      <td>854.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3214</th>\n",
       "      <td>2020-04-27</td>\n",
       "      <td>127.17</td>\n",
       "      <td>87.69</td>\n",
       "      <td>22.33</td>\n",
       "      <td>83.36</td>\n",
       "      <td>41.98</td>\n",
       "      <td>1319.95</td>\n",
       "      <td>6310.70</td>\n",
       "      <td>219.14</td>\n",
       "      <td>2582.43</td>\n",
       "      <td>...</td>\n",
       "      <td>8867.3</td>\n",
       "      <td>37.9</td>\n",
       "      <td>445.1</td>\n",
       "      <td>17.9</td>\n",
       "      <td>4.7</td>\n",
       "      <td>330.2</td>\n",
       "      <td>2167.1</td>\n",
       "      <td>831.3</td>\n",
       "      <td>6046.3</td>\n",
       "      <td>854.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3215</th>\n",
       "      <td>2020-04-28</td>\n",
       "      <td>130.71</td>\n",
       "      <td>88.23</td>\n",
       "      <td>23.16</td>\n",
       "      <td>86.63</td>\n",
       "      <td>41.98</td>\n",
       "      <td>1302.96</td>\n",
       "      <td>6589.34</td>\n",
       "      <td>228.32</td>\n",
       "      <td>2582.43</td>\n",
       "      <td>...</td>\n",
       "      <td>9324.9</td>\n",
       "      <td>41.3</td>\n",
       "      <td>449.6</td>\n",
       "      <td>19.5</td>\n",
       "      <td>4.6</td>\n",
       "      <td>353.3</td>\n",
       "      <td>2205.6</td>\n",
       "      <td>848.4</td>\n",
       "      <td>6113.7</td>\n",
       "      <td>854.3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3216 rows × 313 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Date  AAREAL BANK_TR  COMDIRECT BANK_TR  COMMERZBANK_TR  \\\n",
       "0    2008-01-01          182.27              33.09          974.59   \n",
       "1    2008-01-02          183.81              33.05          956.43   \n",
       "2    2008-01-03          181.73              33.05          944.94   \n",
       "3    2008-01-04          173.31              33.09          939.75   \n",
       "4    2008-01-07          167.91              33.20          943.08   \n",
       "...         ...             ...                ...             ...   \n",
       "3211 2020-04-22          126.90              86.08           21.01   \n",
       "3212 2020-04-23          125.18              87.56           21.56   \n",
       "3213 2020-04-24          127.08              87.16           21.35   \n",
       "3214 2020-04-27          127.17              87.69           22.33   \n",
       "3215 2020-04-28          130.71              88.23           23.16   \n",
       "\n",
       "      DT.PFANDBRIEFBANK_TR  PROCREDIT HOLDING_TR  UMWELTBANK_TR  ALLIANZ_TR  \\\n",
       "0                      NaN                   NaN         260.15     3364.43   \n",
       "1                      NaN                   NaN         259.22     3304.22   \n",
       "2                      NaN                   NaN         261.69     3285.59   \n",
       "3                      NaN                   NaN         263.24     3220.61   \n",
       "4                      NaN                   NaN         259.37     3179.94   \n",
       "...                    ...                   ...            ...         ...   \n",
       "3211                 81.91                 40.14        1387.93     6352.29   \n",
       "3212                 81.53                 40.47        1382.27     6220.43   \n",
       "3213                 80.14                 40.81        1348.28     6189.82   \n",
       "3214                 83.36                 41.98        1319.95     6310.70   \n",
       "3215                 86.63                 41.98        1302.96     6589.34   \n",
       "\n",
       "      DEUTSCHE BANK_TR  BANQUE NATIONALE DE BELGIQUE_TR  ...  \\\n",
       "0              1937.46                          2658.11  ...   \n",
       "1              1900.87                          2684.50  ...   \n",
       "2              1900.00                          2682.82  ...   \n",
       "3              1881.60                          2641.91  ...   \n",
       "4              1880.52                          2632.54  ...   \n",
       "...                ...                              ...  ...   \n",
       "3211            201.17                          2595.15  ...   \n",
       "3212            206.42                          2620.59  ...   \n",
       "3213            196.74                          2582.43  ...   \n",
       "3214            219.14                          2582.43  ...   \n",
       "3215            228.32                          2582.43  ...   \n",
       "\n",
       "      CLOSE BROTHERS GROUP_PI  VIRGIN MONEY UK_PI  HSBC HOLDINGS_PI  \\\n",
       "0                      8202.5                 NaN             784.5   \n",
       "1                      8198.2                 NaN             778.0   \n",
       "2                      8202.5                 NaN             781.2   \n",
       "3                      8332.0                 NaN             771.0   \n",
       "4                      8336.3                 NaN             776.1   \n",
       "...                       ...                 ...               ...   \n",
       "3211                   9005.5                34.6             433.6   \n",
       "3212                   9204.0                35.6             438.7   \n",
       "3213                   9005.5                35.1             430.0   \n",
       "3214                   8867.3                37.9             445.1   \n",
       "3215                   9324.9                41.3             449.6   \n",
       "\n",
       "      LLOYDS BANKING GROUP_PI  METRO BANK_PI  ROYAL BANK OF SCTL.GP._PI  \\\n",
       "0                       137.4            NaN                    11418.8   \n",
       "1                       136.5            NaN                    11264.5   \n",
       "2                       137.3            NaN                    11380.3   \n",
       "3                       132.5            NaN                    10885.2   \n",
       "4                       131.6            NaN                    10756.6   \n",
       "...                       ...            ...                        ...   \n",
       "3211                     17.6            4.7                      321.6   \n",
       "3212                     17.9            4.6                      326.9   \n",
       "3213                     17.5            4.5                      321.3   \n",
       "3214                     17.9            4.7                      330.2   \n",
       "3215                     19.5            4.6                      353.3   \n",
       "\n",
       "      STANDARD CHARTERED_PI  ADMIRAL GROUP_PI  ALLIANCE TRUST_PI  \\\n",
       "0                    8372.5             400.0             3044.2   \n",
       "1                    8322.5             398.2             3037.9   \n",
       "2                    8286.2             400.0             3059.0   \n",
       "3                    8181.8             388.4             2991.6   \n",
       "4                    8209.0             384.4             2993.7   \n",
       "...                     ...               ...                ...   \n",
       "3211                 2165.4             830.2             5894.7   \n",
       "3212                 2216.9             828.4             5920.0   \n",
       "3213                 2128.7             839.3             5861.1   \n",
       "3214                 2167.1             831.3             6046.3   \n",
       "3215                 2205.6             848.4             6113.7   \n",
       "\n",
       "      SAGA GROUP_PI  \n",
       "0             854.3  \n",
       "1             854.3  \n",
       "2             854.3  \n",
       "3             854.3  \n",
       "4             854.3  \n",
       "...             ...  \n",
       "3211          854.3  \n",
       "3212          854.3  \n",
       "3213          854.3  \n",
       "3214          854.3  \n",
       "3215          854.3  \n",
       "\n",
       "[3216 rows x 313 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bank_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "31219fb3-fa79-49ce-954e-54db386f61d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3847"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Since we have different Fama-French factors for EU and US banks we will define which banks are form the US,\n",
    "# also since we know that both banks_pi and banks_ri have the same number of us banks its indifferent form wich\n",
    "# file we get this info\n",
    "us_banks = []\n",
    "banks_pi = pd.ExcelFile(\"data/banks_data_bocconi/banks_ri.xlsm\")\n",
    "us_banks_raw = list(banks_pi.parse(\"US\").columns)[1:]\n",
    "for bank in us_banks_raw:\n",
    "    us_banks.append(bank[:-17])\n",
    "\n",
    "# Delete banks_pi and us_banks_raw to free memory\n",
    "del banks_pi, us_banks_raw\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "97a1b342-5d44-4a95-af8a-7af0bf0a2645",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EU: 7893\n",
      "EU: 3216\n",
      "US: 7893\n",
      "US: 3216\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>Mkt-RF_EU</th>\n",
       "      <th>SMB_EU</th>\n",
       "      <th>HML_EU</th>\n",
       "      <th>RF_EU</th>\n",
       "      <th>Mkt-RF_US</th>\n",
       "      <th>SMB_US</th>\n",
       "      <th>HML_US</th>\n",
       "      <th>RF_US</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2008-01-01</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2008-01-02</td>\n",
       "      <td>-0.11</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.01</td>\n",
       "      <td>-1.25</td>\n",
       "      <td>0.09</td>\n",
       "      <td>-0.22</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2008-01-03</td>\n",
       "      <td>-0.13</td>\n",
       "      <td>-0.22</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.01</td>\n",
       "      <td>-0.03</td>\n",
       "      <td>-0.66</td>\n",
       "      <td>-0.42</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2008-01-04</td>\n",
       "      <td>-1.74</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.01</td>\n",
       "      <td>-2.59</td>\n",
       "      <td>-0.45</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2008-01-07</td>\n",
       "      <td>-0.79</td>\n",
       "      <td>-1.03</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.02</td>\n",
       "      <td>-0.22</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3211</th>\n",
       "      <td>2020-04-22</td>\n",
       "      <td>1.29</td>\n",
       "      <td>-0.77</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.27</td>\n",
       "      <td>-0.45</td>\n",
       "      <td>-1.10</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3212</th>\n",
       "      <td>2020-04-23</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.13</td>\n",
       "      <td>1.03</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3213</th>\n",
       "      <td>2020-04-24</td>\n",
       "      <td>-0.33</td>\n",
       "      <td>0.40</td>\n",
       "      <td>-0.37</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.40</td>\n",
       "      <td>0.35</td>\n",
       "      <td>-0.33</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3214</th>\n",
       "      <td>2020-04-27</td>\n",
       "      <td>1.89</td>\n",
       "      <td>-0.58</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.75</td>\n",
       "      <td>1.90</td>\n",
       "      <td>1.37</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3215</th>\n",
       "      <td>2020-04-28</td>\n",
       "      <td>1.36</td>\n",
       "      <td>-0.46</td>\n",
       "      <td>1.12</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.31</td>\n",
       "      <td>1.13</td>\n",
       "      <td>2.32</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3216 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           date  Mkt-RF_EU  SMB_EU  HML_EU  RF_EU  Mkt-RF_US  SMB_US  HML_US  \\\n",
       "0    2008-01-01       0.02    0.00    0.00   0.01       0.04    0.05    0.01   \n",
       "1    2008-01-02      -0.11    0.94    0.23   0.01      -1.25    0.09   -0.22   \n",
       "2    2008-01-03      -0.13   -0.22    0.11   0.01      -0.03   -0.66   -0.42   \n",
       "3    2008-01-04      -1.74    0.39    0.30   0.01      -2.59   -0.45    0.29   \n",
       "4    2008-01-07      -0.79   -1.03    0.16   0.01       0.02   -0.22    0.24   \n",
       "...         ...        ...     ...     ...    ...        ...     ...     ...   \n",
       "3211 2020-04-22       1.29   -0.77    0.11   0.00       2.27   -0.45   -1.10   \n",
       "3212 2020-04-23       0.42    0.66    0.92   0.00       0.13    1.03    0.54   \n",
       "3213 2020-04-24      -0.33    0.40   -0.37   0.00       1.40    0.35   -0.33   \n",
       "3214 2020-04-27       1.89   -0.58    0.44   0.00       1.75    1.90    1.37   \n",
       "3215 2020-04-28       1.36   -0.46    1.12   0.00      -0.31    1.13    2.32   \n",
       "\n",
       "      RF_US  \n",
       "0      0.01  \n",
       "1      0.01  \n",
       "2      0.01  \n",
       "3      0.01  \n",
       "4      0.01  \n",
       "...     ...  \n",
       "3211   0.00  \n",
       "3212   0.00  \n",
       "3213   0.00  \n",
       "3214   0.00  \n",
       "3215   0.00  \n",
       "\n",
       "[3216 rows x 9 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now we read the Fama-French files with the factos and add them\n",
    "# First we get the start and end date of our bank data\n",
    "start = bank_data[\"Date\"].iloc[0]\n",
    "end = bank_data[\"Date\"].iloc[-1]\n",
    "\n",
    "# And now we can read in the Factors and keep only the days we need\n",
    "EU_FF = pd.read_excel(\"data/banks_data_bocconi/Europe_3_Factors_Daily.xlsx\")\n",
    "print(\"EU:\", len(EU_FF))\n",
    "EU_FF['date'] = pd.to_datetime(EU_FF['date'], format=\"%m/%d/%Y\")\n",
    "EU_FF = EU_FF[(EU_FF[\"date\"] >= start) & (EU_FF[\"date\"] <= end)]\n",
    "rename_dict_EU = {\"date\": \"date\"}\n",
    "for col in EU_FF.columns[1:]:\n",
    "    rename_dict_EU[col] = col + \"_EU\"\n",
    "EU_FF.rename(columns=rename_dict_EU, inplace=True)\n",
    "print(\"EU:\", len(EU_FF))\n",
    "\n",
    "US_FF = pd.read_excel(\"data/banks_data_bocconi/North_America_3_Factors_Daily.xlsx\")\n",
    "print(\"US:\", len(US_FF))\n",
    "US_FF['date'] = pd.to_datetime(US_FF['date'], format=\"%m/%d/%Y\")\n",
    "US_FF = US_FF[(US_FF[\"date\"] >= start) & (US_FF[\"date\"] <= end)]\n",
    "US_FF.drop(\"date\", axis = 1, inplace = True)\n",
    "rename_dict_US = {}\n",
    "for col in US_FF.columns:\n",
    "    rename_dict_US[col] = col + \"_US\"\n",
    "US_FF.rename(columns=rename_dict_US, inplace=True)\n",
    "print(\"US:\", len(US_FF))\n",
    "\n",
    "FF = pd.concat([EU_FF, US_FF], axis = 1)\n",
    "FF.reset_index(drop = True, inplace = True)\n",
    "FF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f72d285c-0ba4-4dd9-96e3-656a55b35099",
   "metadata": {},
   "outputs": [],
   "source": [
    "bank_data_complete = pd.concat([bank_data, FF], axis = 1)\n",
    "bank_data_complete.drop([\"date\"], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bbce44e-5f26-4200-99fe-ff591269a12f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b05cda7-bf01-49d3-8fc6-d7975d8e55fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "782df3ec-900a-4527-8e20-d61bae641822",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28bb8e94-4b82-4e77-acea-36830915621f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e0e10cf-d58b-4b07-9566-ac7a60e38792",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Before we estimate the CAPM we need to define market returns and the risk free"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49e35e63-cd9f-4bdf-9192-76b584a25a08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Suppress warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "def estimateCAPM(returns_df):\n",
    "    # Initialize an empty DataFrame to store results\n",
    "    CAPM_df = pd.DataFrame()  \n",
    "     # Loop through all stock columns, excluding the Date and sp500\n",
    "    for stock in list(returns_df.columns)[1:-1]: \n",
    "        stock_i = returns_df[f\"{stock}\"]  \n",
    "        mkt = returns_df[\"sp500_r\"]\n",
    "        \n",
    "        # Add a constant term (intercept) to the regression model, this will be our Alpha\n",
    "        X = sm.add_constant(mkt)  \n",
    "        # Fit the OLS regression\n",
    "        model = sm.OLS(stock_i, X).fit()  \n",
    "    \n",
    "        # Extract parameter of intrest\n",
    "        alpha = model.params[0]\n",
    "        beta = model.params[1]\n",
    "        p_value_alpha = model.pvalues[0]\n",
    "        p_value_beta = model.pvalues[1]\n",
    "    \n",
    "        # Create a dictionary to store the results for the current stock\n",
    "        result_i = {\"Alpha\": alpha,\n",
    "                    \"Beta\": beta,\n",
    "                    \"P Value Alpha\": p_value_alpha,\n",
    "                    \"P Value Beta\": p_value_beta}\n",
    "    \n",
    "        # Convert result_i to a DataFrame and concatenate it to CAPM_df\n",
    "        result_df = pd.DataFrame(result_i, index=[stock])  \n",
    "        CAPM_df = pd.concat([CAPM_df, result_df])  \n",
    "\n",
    "CAPM_df.reset_index(inplace = True)\n",
    "CAPM_df.rename(columns={'index': 'Stock'}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e2277a3-b1bc-4445-9315-2e4df8fb29ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = int(0.7 * len(banks_ri_df))\n",
    "\n",
    "# Drop columns that don't meet the threshold\n",
    "banks_ri_df.dropna(axis=1, thresh=threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8e6aac6-658e-4566-ad66-e1de113f01e5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
